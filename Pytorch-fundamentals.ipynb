{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9fb9e6-9bbf-48c7-a85d-f7b5b2f7c47f",
   "metadata": {},
   "source": [
    "Pytorch is used for machine leaning and deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153453af-2fa4-49b0-b549-abda6750d9e4",
   "metadata": {},
   "source": [
    "What is deep learning?\n",
    "It is a subset of machine learning, turning data (images, text) into numbers and finding patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "d325fe31-98fe-43ca-88af-4d034b824bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218433e5-5282-419b-89de-adcaddc3a2a2",
   "metadata": {},
   "source": [
    "Now that we have imported the nessacary libraries, we can begin with coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f371a309-1a70-445f-b770-438f52aad797",
   "metadata": {},
   "source": [
    "**We will first start with tensor which is a way to represent data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "3f6a784e-5480-47af-869c-2a03d2394e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "#First kind of tensor is a scalar\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d016f-fce5-4bbb-91dc-0af882ed7652",
   "metadata": {},
   "source": [
    "A scalar has no dimenstions therefore it outputs only one number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "c0c65d58-cb15-4b12-82e8-74e2a765489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(scalar.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "353143ed-6805-49ce-9889-7d95abb99e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "ad72eabd-1894-4ff6-8d37-011841e302f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n"
     ]
    }
   ],
   "source": [
    "# The other thing is a vector\n",
    "vector = torch.tensor([7,7])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "bcaeb102-6595-496b-b6f4-8062636189ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(vector.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a93af-a96f-4aa5-89ca-d25872a800fb",
   "metadata": {},
   "source": [
    "So a basic idea of how many dimensions does a vector has is just to count the number square brackets in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9203b842-8553-4231-ae6f-e47ca012ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b708bf-67c6-4410-9c51-0a1fd677389b",
   "metadata": {},
   "source": [
    "vector.shape tells us how many elements are there in the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd291cf4-d4d0-4b08-bcec-5c6eed76f673",
   "metadata": {},
   "source": [
    "**Now lets explore a Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "6c5cda38-9fdb-44c8-ba6a-ed4aad76aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[7,8], [9, 10]])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "a63d6376-4407-4a4a-89e0-375b2ab6f8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "e6dc7eb6-ddc8-461c-ba21-c38fdac075a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "7d7fbfb2-94ec-4508-ac4b-d8fafaf439cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a94eb0e-e4b6-4fa5-8775-49f9d1c8c21e",
   "metadata": {},
   "source": [
    "The above gives the positional vectors in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "4d710aee-7562-41fb-984b-f4c3324f837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape\n",
    "# number of elements in each vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dffd2fc-94db-4890-9968-ba8a0e4d863c",
   "metadata": {},
   "source": [
    "**Now lets go over tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "0955564a-8fff-4d7d-afc9-5da8958ab510",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[[1,2,3],[2,5,4],[6,9,7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "a141add3-13a5-432c-b9d7-ea176b637cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [2, 5, 4],\n",
       "         [6, 9, 7]]])"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "e5adc889-a0f2-4cba-ac99-c0192ead90b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "db040096-9fca-4bc5-b27b-6e2e2e6b18a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17620fbd-df9d-4f88-bc74-6bc50ccb0d38",
   "metadata": {},
   "source": [
    "Now the shape confuses a bit but this simple says we have a one 3x3 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e49d4-585d-4b92-9ba7-e797a4647400",
   "metadata": {},
   "source": [
    "**SO ABOVE WE HAVE LEARNED THE BASICS OF PYTORCH**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1496cd5-6ecd-438b-83f7-d5d4e3100511",
   "metadata": {},
   "source": [
    "No the common nomanclature is to represents a matrix or a tensor use a whole capital letter word, \n",
    "where as use lower case variable name for scalar and vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12ff1a-6e67-4cbe-bd11-5027b46c65a4",
   "metadata": {},
   "source": [
    "**Random tensors**\n",
    "\n",
    "why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "start with random numbes ---> look at data ---> update random numbers ---> look at data ---> update random numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "845c08ae-8bb1-408d-8906-689606f4180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random tensor of size (3, 4)\n",
    "\n",
    "random_tensor = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "a3b14979-e240-4b62-8308-6d644872e19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
       "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
       "        [0.2696, 0.4414, 0.2969, 0.8317]])"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a92aa-ce04-4827-861c-4df9b58b8566",
   "metadata": {},
   "source": [
    "So we have 3 rows and 4 columns with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "66bf2db0-cc26-4de3-bf7a-52e53b658da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "d1a9c895-5b8e-4dd6-a1d6-1e93aa629544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "be2b9c44-f1eb-4f3a-9285-cfc32a04baf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224)) # height, width, color channel\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f0e7c-68ed-48f4-ba90-963b753794ab",
   "metadata": {},
   "source": [
    "By the above we can see we can turn anything into a tensor, for example an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9985f9f-0e3b-426a-a7f2-210c95221445",
   "metadata": {},
   "source": [
    "**Tensor of zeros and ones**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "dc9103d5-8f9c-4a36-859b-e200fa4e4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(size=(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "0388275f-a539-4cf3-b949-8eae2a4e030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5dbefa-7023-4f0e-be07-0a1894423911",
   "metadata": {},
   "source": [
    "With such zeros and ones we can mask anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "df642206-4e65-4f9d-b3dc-a80423820965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2cf00-4287-41cd-b9b8-930de29e22e0",
   "metadata": {},
   "source": [
    "Create a tensor of ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "08cbf1d4-d5b9-43a6-91f5-4e8ea5054aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "10986cd3-8dbe-450d-b9e9-975cb344ee3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d833a-3a54-4531-98c7-254d9d629732",
   "metadata": {},
   "source": [
    "We can also see the datatype of a tensor by using .dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "52afa431-f17e-45c2-800d-c48a71ae7fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c808b-2a52-4ea9-8afa-b37a8aadfcfd",
   "metadata": {},
   "source": [
    "**Now lets create a range of tensors and tensor-like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "da98c18c-fded-488e-b980-28e92ba22cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range()\n",
    "torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e4add-6635-474d-b142-f283fe2c8b6f",
   "metadata": {},
   "source": [
    "This gives a range for values from 0 to 9 excluding 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13b317-ecc4-4f1f-9ed6-8a0447baa9de",
   "metadata": {},
   "source": [
    "We can also put a step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "c49e7333-6744-4603-832c-70bc062eb209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(0,11,1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "a81ba859-d251-465e-b930-37d166940e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also create tensor like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8463a-ccc9-4e82-934c-e37520499193",
   "metadata": {},
   "source": [
    " So .zeros_like made the tensor fill with zeroes but with the same range like the range in one_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06785a4-1904-4e57-af58-23b5f99d16a9",
   "metadata": {},
   "source": [
    "**Tensor datatypes**\n",
    "**Note**: Tensor datatypes is one of the 3 big errors you'll run into with Pytorch & deep learning:\n",
    "1. Tensor not right datatype\n",
    "2. Tensor not right shape\n",
    "3. Tensor not on the right device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "53e7614f-1c9c-418f-86ed-faf386d699fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None, device=None, requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f96d-3f51-48b2-9c11-97cb5d2c1f40",
   "metadata": {},
   "source": [
    "The device is used because during a computation, one tensor might live on the GPU while the other lives on the CPU, computing them with throw and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "31423b64-9ddc-4034-9d87-e405b336ffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Converting the datatype\n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "5f22b7c6-7b83-4ec2-b8f4-14bcd3f275c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can multiply two tensors of different datatype\n",
    "float_32_tensor * float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "da8bbde0-23b2-4bd1-96a9-272c27fd6962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "cedad24e-60ad-4a60-9294-96e235d4c48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f69f5af-f784-4b9f-8cad-8a9612bd7e6f",
   "metadata": {},
   "source": [
    "**Getting information from tensors**\n",
    "\n",
    "1. Tensors not right datatype - to do get datatype from a tensor, can use tensor.dtype\n",
    "2. Tensors not right shape - to get shape from a tensor, can use tensor.shape\n",
    "3. Tensors not no the right device - to get device a tensor, can use tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "e6768113-ee9b-4e79-a182-e62fc0080365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5745, 0.9200, 0.3230, 0.8613],\n",
       "        [0.0919, 0.3102, 0.9536, 0.6002],\n",
       "        [0.0351, 0.6826, 0.3743, 0.5220]])"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # create a random tensor\n",
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "19561003-7562-4850-8192-bcf1719b6ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5745, 0.9200, 0.3230, 0.8613],\n",
      "        [0.0919, 0.3102, 0.9536, 0.6002],\n",
      "        [0.0351, 0.6826, 0.3743, 0.5220]])\n",
      "Datatype of tensor: (some_tensor.dtype)\n",
      "Shape of tensor: (some_tensor.shape)\n",
      "Device tensor is on: (some_tensor.device)\n"
     ]
    }
   ],
   "source": [
    "# find out some detail of a tensor\n",
    "print(some_tensor)\n",
    "print(f'Datatype of tensor: (some_tensor.dtype)')\n",
    "print(f'Shape of tensor: (some_tensor.shape)')\n",
    "print(f'Device tensor is on: (some_tensor.device)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a6c87-7106-428d-9742-25f1871016fc",
   "metadata": {},
   "source": [
    "**Manupliating Tensors**\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix manupliation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "3e170226-da62-4744-80cc-47ada2c73951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "6f669b9e-cd53-4860-b213-dc197c7366f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "f0170647-b802-40ad-b8ec-4356158783e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract \n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "89b3d95f-07a8-446b-afc1-5e732c8d392c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also try Pytorch builtin functions\n",
    "torch.mul(tensor, 10) # mul short for multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "81c13b87-158f-4d0b-af8c-b3d37c98a891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000])"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 2) # div short for division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "9da8a460-5199-4ed2-8703-f8910f3f3d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  0,  1])"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 2) # sub short for substraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c523c4-1a31-45df-a34e-f41f41db3357",
   "metadata": {},
   "source": [
    "****Matrix Multiplication****\n",
    "\n",
    "There are two ways of matrix multiplication in neural networks and deep learning\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplication need to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "   * (3, 2) @ (3, 2) won't work\n",
    "   * (2, 3) @ (3, 2) will work\n",
    "2. The resulting matrix has the shape of the **outer dimension**:\n",
    "   * (2, 3) @ (3, 2) -> (2, 2)\n",
    "   * (3, 2) @ (2, 3) -> (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "eced5371-51d4-4d51-a93a-5b9f9c391f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, '*', tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "7e56792d-6d60-427d-9655-7cab987962de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "d5b6290d-f887-414b-a986-b9c989212e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplying by hand\n",
    "1 * 1 + 2 * 2 + 3 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "09cdcd66-c5a3-4e39-a209-2641b0951e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 669 μs, sys: 901 μs, total: 1.57 ms\n",
      "Wall time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "dd4df093-dbb3-4aab-87fa-6834a2c61843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 122 μs, sys: 73 μs, total: 195 μs\n",
      "Wall time: 149 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09718537-952e-4963-a07c-a147e95fe406",
   "metadata": {},
   "source": [
    "When we compare the hand written matrix mul code with \n",
    "the pytorch function it is clear torch cumputes it it much less time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69840d5c-41a6-4d73-85df-48b322471fd2",
   "metadata": {},
   "source": [
    "***One of the most common errors in deep learning: Shape errors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "e4a21421-b5fa-4b77-9782-cfa2d2918395",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[736], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m], \n\u001b[1;32m      7\u001b[0m                         [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[1;32m      8\u001b[0m                         [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multipication\n",
    "tensor_A = torch.tensor([[1, 2], \n",
    "                         [3, 4], \n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10], \n",
    "                        [8, 11], \n",
    "                        [9, 12]])\n",
    "\n",
    "# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul\n",
    "torch.matmul(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd24b91-e06f-424e-ac8e-ef5b6015c8d0",
   "metadata": {},
   "source": [
    "**IMPORTANT # torch.mm is the same as torch.matmul (It's an alias)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d16cc-e672-4e44-9cd3-f72c24f6f5ef",
   "metadata": {},
   "source": [
    "We can see we have a shape error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "b228fb07-c611-4e15-b098-1ebda9668198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82592b9f-cda3-4739-a6d3-76638202809e",
   "metadata": {},
   "source": [
    "The inner n does not match, So here we can use **Transpose**\n",
    "\n",
    "A **Tranpose** switches the axis or dimensions of a given tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "4e26c148-c078-438f-a7ca-2b90de786623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "f41e8578-036c-41a6-9da7-92f13004e6b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331342c-9367-4ba1-82e6-a4e4557ebd51",
   "metadata": {},
   "source": [
    "With .T we get the transpose of tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "1ba26a86-d381-46c1-8875-626d245127ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can multiply tensor_A and tensor_B\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "c5587f11-5a1d-4e41-8d64-4c92d7fde841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
      "Output:\n",
      "\n",
      "\n",
      "Output shape: torch.Size([3, 3]) \n"
     ]
    }
   ],
   "source": [
    "#The matrix mm operation works when tensor_B is transposed\n",
    "print(f'Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}')\n",
    "print(f'New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}')\n",
    "print(f'Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match')\n",
    "print('Output:\\n')\n",
    "output = torch.mm(tensor_A, tensor_B.T)\n",
    "print(f'\\nOutput shape: {output.shape} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a35eb7-e7f5-4f29-8992-b0afd3ec5cd1",
   "metadata": {},
   "source": [
    "***MATRIX AGGREGATION**\n",
    "\n",
    "**Finding the min, max, mean, sum, etc (tensor aggregation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "53c5af3e-cabe-4c9b-9c9d-c10a53790dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "db55df4c-bd31-4c93-b9a4-8f49dca092e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "17ff11d0-48ae-40cf-abe9-0de5e3d3baff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "9a7c8343-ba15-437d-a782-34f928bc4030",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[758], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the mean\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmean(x), x\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "# Find the mean\n",
    "torch.mean(x), x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883464b-0585-4ac0-92a1-ef7ccc8e6700",
   "metadata": {},
   "source": [
    "Finally we got the second most common type of error **datatype error**\n",
    "we can resolve this by changing the datatype of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "cccc3ac6-b256-4f49-8664-6079e8f79344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "cf6bfdff-fdf8-4759-9e3b-5bf17e2e144b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e4cdf-300f-4c89-a840-6370a6880997",
   "metadata": {},
   "source": [
    "***Finding the positional min and max***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "afc341aa-4b6d-4c99-afc4-0ceb85b1f9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "46222343-9bf8-416b-b654-69414fc071f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() -> returns index position\n",
    "# of target tensor where minimum value ouccurs\n",
    "x.argmin(), torch.argmin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "74737834-efd7-491c-af7d-59702f2c0531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the maximum value with argmax() -> returns index position\n",
    "# of target tensor where maximum value ouccurs\n",
    "x.argmax(), torch.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8713fa0-08f8-4872-92fc-f35251e41a33",
   "metadata": {},
   "source": [
    "***Reshaping, stacking, squeezing and unsqueezing tensors***\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Returns a view of an input tensor of centain shape but keep the same memory as the     og tensor\n",
    "* Stacking - combine multiple tensors on top of each other (stack) or side by side (hstack)\n",
    "* Squeeze - removes all '1' dimensions from a tensor\n",
    "* Unsqueeze - add a '1' dimension to a target tensor\n",
    "* Permute - Return a view of the inpout with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "454ec177-e643-4637-a2d8-a22ffb81c1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "804a4eb8-5e29-4b7c-b192-c7c1ba11be23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new dimension\n",
    "x_reshaped = x.reshape(1 , 9) # we can reshape in mutiples of the max number of positions in the tensor\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "1d21c92a-fcb1-4b94-afa2-52960ac64115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645b91b-e27e-41e3-bd5b-d83f4a5eabf1",
   "metadata": {},
   "source": [
    "When using .view changing z will the change x (because a view of a tensor shares the same memory as the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "c9c5c31e-b4b8-4eb8-8598-987f1c8284d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       " torch.Size([4, 9]))"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top \n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb0b21-4033-4bd5-92c4-82ad6c94f055",
   "metadata": {},
   "source": [
    "#### squeeze and unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "9099b1cb-45b1-453f-8cc6-6e1e93bb3d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "b9eee260-2856-4df6-9c4f-4a569202deeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze(), x_reshaped.squeeze().shape # removes all single dimensions removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac8eec5-0697-4dd3-872d-c948069ab144",
   "metadata": {},
   "source": [
    " ### Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa9484-b01c-4725-a54b-baccdb518259",
   "metadata": {},
   "source": [
    "Indexing with Pytorch is similar to indexing with NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "464f02ba-763a-4758-811a-0e886bdbfa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "5575a420-8fdb-4673-9ac5-11effafa29e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets index on the new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "f2373ff1-3a32-4fa8-b351-feb08b988278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets index on the middle bracket (dim=1)\n",
    "x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "de37731c-bd9c-4ebc-9b50-7a79a7101016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets index on the most inner bracket (last diminsion)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "781da2a3-d0cd-4648-8fa8-c2d73d4c2ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# challenge get the number 9\n",
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "197b698b-25f6-49d9-9907-b6d29a394572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use ':' to select 'all' of a target dimension\n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "39c26dd4-d65d-4441-9879-aa5cbccb7724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get values of 0th and 1st dimension but only index 1 of the 2nd dimension\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd7ca9-28cb-4bd8-a9e8-687f252b0792",
   "metadata": {},
   "source": [
    "## Pytorch tensors and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330742b4-2d4b-48c4-bf02-6ebf90f4ae7e",
   "metadata": {},
   "source": [
    "NumPy is a popular scientific Python numerical computing library.\n",
    "\n",
    "And because of this, Pytorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPym array, want in Pytorch tensor -> torch.from_numpy(ndarray)\n",
    "* Pytorch tensor -> Numpy -> torch.Tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "0923fe64-45ee-42ac-9ce3-be82f7a06920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # Numpy array to tensor\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0,8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b800a-a995-443f-b912-ea14d235c309",
   "metadata": {},
   "source": [
    "when going from numpy to pytorch the default datatype is float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "26db018e-cf49-4695-afb2-eb028bc3d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of array, what will this do to 'tensor'?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab77e5-7919-4b03-82dd-301c1a39e823",
   "metadata": {},
   "source": [
    "When changing the value of the array the original values of the array will not change and this will reflect on the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "e20b29f8-293f-4b50-97e9-57048774e7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "673db83a-e024-40a6-8e30-6c6f3ba5ed65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the tensor, what happens to 'numpy_tensor'?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a06be0-b598-414b-90dd-e1af6ffcdf7a",
   "metadata": {},
   "source": [
    "When changing the value of the tensor the original values of the tensor will not change and this will reflect on the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c9362-d53b-451e-b415-6b625ab266bd",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "'start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...'\n",
    "\n",
    "to reduce the randomness in neural networks in pytorch comes the concept of a **random seed**\n",
    "\n",
    "Essentially what the random seed does is 'flavour' the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "55318ca4-fa71-4e71-8e56-23bd9cc129c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1336, 0.9666, 0.9754, 0.8474],\n",
      "        [0.8988, 0.1105, 0.4563, 0.9719],\n",
      "        [0.3968, 0.1496, 0.4743, 0.9973]])\n",
      "tensor([[0.4436, 0.9726, 0.5194, 0.5337],\n",
      "        [0.7050, 0.3362, 0.7891, 0.1694],\n",
      "        [0.1800, 0.7177, 0.6988, 0.5510]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "## create two random tensors\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "2c88283f-297e-4cce-bbe9-ca3691b32c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Lets make some random but reproduceable tensors\n",
    "import torch\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cac5f-5908-4736-9eee-a6a832fed186",
   "metadata": {},
   "source": [
    "## Runnign tensors and Pytorch objects on the GPUs (and making faster computations)\n",
    "\n",
    "GPU = faster computation on numbers, thanks to CUDA + NVIDIA hardware + Pytorch working behind the scenes to make everything hunky dory (good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844152d1-2a15-4418-9fbd-781c28c80b10",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - Use Jupyter for a free GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59c994-4beb-4227-b8c7-3942550d39cc",
   "metadata": {},
   "source": [
    "### Check for GPU access with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "9973d77e-9e87-42a2-8eea-04b7bcbb7094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with pytorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549ac7f-79c5-40aa-a979-15975ff2aacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8246e-3a6e-4dab-adc2-2b6594adbd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf899d8-2193-4442-a216-e12f8b0bcd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d5666-5348-47d6-9821-e8f83dfb6a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26baf7eb-0fd9-40e6-9f03-a5931d459474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0f584-2759-4767-afd5-61b5775b58e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e7776-57bb-441a-baac-53815e90327b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0af7af-9ba0-4ce8-922f-6e60f8e73424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efef96b-4ce7-433a-99a2-b0d53ad57af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396798c-cb34-4661-97b4-e9630f5c1069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0556158-f997-489a-99db-4c8717c249d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e392a5-d5d3-4bfe-9c27-6ca2817ed00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f16f4-fd02-4c20-8c24-8ac8a499d0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9bf6a-b32d-4668-9938-8156e053488e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a759a-1e69-4eb0-b14e-e31a1c990997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b0cd00-df83-4844-ac19-e10c9f5d7b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454a1c4-1ec8-4446-8d5d-7f0594f02d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb735259-3341-4db0-be93-0d162adbbe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab7c81-b2dd-4a1d-880f-05a6a5131156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e6a67-f8fd-4a7e-a486-66021e025b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fc663-d5bb-4f27-a0ae-54d86218f57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50dfd77-f881-48b6-893e-e99a28005b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9ae09-27fe-4a5a-9afe-bb4a8a8581a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5edadc-2952-4ba4-bc5e-f60dcd4cd00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45661730-12d1-492a-9966-66bb613036fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c548bf-0b3d-4c3e-bbe9-f693418f2b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6c34a-558d-4cf2-8748-ee966f10934e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e0e11-138e-4236-b5ed-0e66cc1380cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0657d1e-91ae-4dfc-b9f1-26f43b8bf2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
